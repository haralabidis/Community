{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EdgeBadge Speech Recognition Training Notebook",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haralabidis/Community/blob/master/EdgeBadge_Speech_Recognition_Training_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNFWX4V3Zu7s",
        "colab_type": "text"
      },
      "source": [
        "# EdgeBadge Speech Recognition Training Notebook\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCxaBA1gJICK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "This notebook demonstrates how to train a 20kb [Simple Audio Recognition](https://www.tensorflow.org/tutorials/sequences/audio_recognition) model for [TensorFlow Lite for Microcontrollers](https://tensorflow.org/lite/microcontrollers/overview). It will produce the same model used in the [micro_speech](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/micro/examples/micro_speech) example application.\n",
        "\n",
        "The model is designed to be used with [Google Colaboratory](https://colab.research.google.com).\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/drive/1cR5JJNYzWLlgSK9c16nnFLhxtW_bmO-p#offline=true&sandboxMode=true\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/micro/examples/micro_speech/train_speech_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mpixtCtJPHk",
        "colab_type": "text"
      },
      "source": [
        "The notebook runs Python scripts to train and freeze the model, and uses the TensorFlow Lite converter to convert it for use with TensorFlow Lite for Microcontrollers.\n",
        "\n",
        "**Training is much faster using GPU acceleration.** Before you proceed, ensure you are using a GPU runtime by going to **Runtime -> Change runtime type** and selecting **GPU**. Training 18,000 iterations will take 1.5-2 hours on a GPU runtime.\n",
        "\n",
        "## Configure training\n",
        "\n",
        "The following `os.environ` lines can be customized to set the words that will be trained for, and the steps and learning rate of the training. The default values will result in the same model that is used in the micro_speech example. Run the cell to set the configuration:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMjI2a-4IsyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# A comma-delimited list of the words you want to train for.\n",
        "# The options are: yes,no,up,down,left,right,on,off,stop,go\n",
        "# All other words will be used to train an \"unknown\" category.\n",
        "WANTED_WORDS = [\"up\", \"down\"]\n",
        "\n",
        "# The number of steps and learning rates can be specified as comma-separated\n",
        "# lists to define the rate at each stage. For example,\n",
        "# TRAINING_STEPS=15000,3000 and LEARNING_RATE=0.001,0.0001\n",
        "# will run 18,000 training loops in total, with a rate of 0.001 for the first\n",
        "# 15,000, and 0.0001 for the final 3,000.\n",
        "TRAINING_STEPS = [15000, 3000]\n",
        "LEARNING_RATE = [\"0.001\", \"0.0001\"]\n",
        "\n",
        "# Calculate the total number of steps, which is used to identify the checkpoint\n",
        "# file name.\n",
        "TOTAL_STEPS = sum(TRAINING_STEPS)\n",
        "\n",
        "# Print the configuration to confirm it\n",
        "!echo \"Training these words: {WANTED_WORDS}\"\n",
        "!echo \"Training steps in each stage: {TRAINING_STEPS}\"\n",
        "!echo \"Learning rate in each stage: {LEARNING_RATE}\"\n",
        "!echo \"Total number of training steps: {TOTAL_STEPS}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT4hbq-GSgD4",
        "colab_type": "text"
      },
      "source": [
        "# Connect to Google Drive\n",
        "\n",
        "This section connects the notebook with your Google Drive. Since Colab instances are ephemeral, we need somewhere more permanent to store the trained ML model. Running this cell mounts your Google Drive just like a regular folder at `/content/drive`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf-psq8uJeou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os.path\n",
        "from google.colab import drive\n",
        "\n",
        "DRIVE_STORAGE_PATH = '/content/drive/My Drive/speech-recognition'\n",
        "\n",
        "def ensure_drive():\n",
        "  if not os.path.exists('/content/drive/My Drive'):\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    \n",
        "ensure_drive()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej9eyTYtI_RR",
        "colab_type": "text"
      },
      "source": [
        "## Install dependencies\n",
        "\n",
        "Next, we'll install a GPU build of TensorFlow, so we can use GPU acceleration for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd1iM1o2ymvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replace Colab's default TensorFlow install with the pinned version used\n",
        "# for speech training.\n",
        "!pip uninstall -y tensorflow tensorflow_estimatorpip uninstall -y tensorflow tensorflow_estimator tensorboard\n",
        "!pip install -q tf-estimator-nightly==1.14.0.dev2019072901 tensorflow-gpu==1.15 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfoVL_lYaRkU",
        "colab_type": "text"
      },
      "source": [
        "## Download TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT6PCd82J4BO",
        "colab_type": "text"
      },
      "source": [
        "We'll also clone the TensorFlow repository, which contains the scripts that train and freeze the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etSLy5EcZsp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone the repository from GitHub\n",
        "!git clone -q https://github.com/tensorflow/tensorflow\n",
        "# Check out a commit that has been tested to work\n",
        "# with the build of TensorFlow we're using\n",
        "!git -c advice.detachedHead=false -C tensorflow checkout -f 17ce384df70\n",
        "#!git -c advice.detachedHead=false -C tensorflow checkout -f r1.14\n",
        "\n",
        "import subprocess\n",
        "subprocess.run(\n",
        "    ['git', '-C', 'tensorflow', 'apply', '-'],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.PIPE,\n",
        "    encoding='utf-8',\n",
        "    check=True,\n",
        "    input=\"\"\"\\\n",
        "diff --git a/tensorflow/examples/speech_commands/train.py b/tensorflow/examples/speech_commands/train.py\n",
        "index 446e351cb8..431c2d3d34 100644\n",
        "--- a/tensorflow/examples/speech_commands/train.py\n",
        "+++ b/tensorflow/examples/speech_commands/train.py\n",
        "@@ -234,7 +234,7 @@ def main(_):\n",
        "             dropout_prob: 0.5\n",
        "         })\n",
        "     train_writer.add_summary(train_summary, training_step)\n",
        "-    tf.compat.v1.logging.info(\n",
        "+    tf.compat.v1.logging.debug(\n",
        "         'Step #%d: rate %f, accuracy %.1f%%, cross entropy %f' %\n",
        "         (training_step, learning_rate_value, train_accuracy * 100,\n",
        "          cross_entropy_value))\n",
        "\"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep7TSCcFaavF",
        "colab_type": "text"
      },
      "source": [
        "## Create trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1O64yp5zBle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "\n",
        "wanted_words_str = ','.join(WANTED_WORDS)\n",
        "training_steps_str = ','.join([str(x) for x in TRAINING_STEPS])\n",
        "learning_rate_str = ','.join(LEARNING_RATE)\n",
        "\n",
        "TRAINING_RUN_NAME=\"{}-{}\".format(\n",
        "    wanted_words_str, datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\"))\n",
        "TRAIN_DIR = f'{DRIVE_STORAGE_PATH}/{TRAINING_RUN_NAME}'\n",
        "!mkdir -p \"{TRAIN_DIR}\"\n",
        "\n",
        "# Suppress INFO messages from C++ logging--these will slow down Colab and \n",
        "# eventually crash the browser.\n",
        "#--verbosity=INFO \\\n",
        "!python tensorflow/tensorflow/examples/speech_commands/train.py \\\n",
        "--model_architecture=tiny_conv --window_stride=20 --preprocess=micro \\\n",
        "--wanted_words={wanted_words_str} --silence_percentage=25 \\\n",
        "--unknown_percentage=25 --quantize=1 \\\n",
        "--how_many_training_steps={training_steps_str} \\\n",
        "--learning_rate={learning_rate_str} --summaries_dir=/content/retrain_logs \\\n",
        "--data_dir=/content/speech_dataset --train_dir=\"{TRAIN_DIR}\"\n",
        "\n",
        "!python tensorflow/tensorflow/examples/speech_commands/freeze.py \\\n",
        "--model_architecture=tiny_conv --window_stride=20 --preprocess=micro \\\n",
        "--wanted_words={wanted_words_str} --quantize=1 \\\n",
        "--output_file=\"{TRAIN_DIR}/tiny_conv.pb\" \\\n",
        "--start_checkpoint=\"{TRAIN_DIR}/tiny_conv.ckpt-{TOTAL_STEPS}\"\n",
        "\n",
        "!toco \\\n",
        "--graph_def_file=\"{TRAIN_DIR}/tiny_conv.pb\" \\\n",
        "--output_file=\"{TRAIN_DIR}/tiny_conv.tflite\" \\\n",
        "--input_shapes=1,49,40,1 --input_arrays=Reshape_2 \\\n",
        "--output_arrays='labels_softmax' \\\n",
        "--inference_type=QUANTIZED_UINT8 --mean_values=0 --std_dev_values=9.8077\n",
        "\n",
        "print('Training completed')\n",
        "print(f'The frozen graph is: {TRAIN_DIR}/tiny_conv.pb')\n",
        "print(f'The tflite graph is: {TRAIN_DIR}/tiny_conv.tflite')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSwVAMRFOFE4",
        "colab_type": "text"
      },
      "source": [
        "## Spot checks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HqVZ9-j8FBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os.path\n",
        "if not os.path.exists('/content/speech_dataset'):\n",
        "  !wget https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz\n",
        "  !mkdir /content/speech_dataset\n",
        "  !tar -xzf speech_commands_v0.02.tar.gz -C /content/speech_dataset\n",
        "\n",
        "ensure_drive()\n",
        "\n",
        "\n",
        "for phrase in ('on', 'off', 'stop', 'go', 'right'):\n",
        "  wav = !ls -1 /content/speech_dataset/{phrase}/*.wav | head -n 1\n",
        "  wav = wav[0]\n",
        "\n",
        "  print('')\n",
        "  print(f'{phrase:10s} <' + '-' * 69)\n",
        "  !cd tensorflow && python tensorflow/examples/speech_commands/label_wav.py --graph=\"{TRAIN_DIR}/tiny_conv.pb\" --labels=\"{TRAIN_DIR}/tiny_conv_labels.txt\" --wav={wav} 2>/dev/null\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}